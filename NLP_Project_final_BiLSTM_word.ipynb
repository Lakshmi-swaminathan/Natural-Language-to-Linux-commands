{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1l7sjKmznQiKMsDSY-1Ukiv7thQQuw-og","timestamp":1714340273268}],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyPYgrGrQiuCIIHldrCr6jtO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yXts04b_FhJm","executionInfo":{"status":"ok","timestamp":1714340409272,"user_tz":240,"elapsed":63232,"user":{"displayName":"Lakshmi Swaminathan","userId":"16891025941418371210"}},"outputId":"1f2c3251-18e9-48d8-cd1f-8e511da285cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-text\n","  Downloading tensorflow_text-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow<2.17,>=2.16.1 (from tensorflow-text)\n","  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (0.2.0)\n","Collecting h5py>=3.10.0 (from tensorflow<2.17,>=2.16.1->tensorflow-text)\n","  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m114.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (18.1.1)\n","Collecting ml-dtypes~=0.3.1 (from tensorflow<2.17,>=2.16.1->tensorflow-text)\n","  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (2.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (4.11.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (1.14.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (1.62.2)\n","Collecting tensorboard<2.17,>=2.16 (from tensorflow<2.17,>=2.16.1->tensorflow-text)\n","  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras>=3.0.0 (from tensorflow<2.17,>=2.16.1->tensorflow-text)\n","  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (0.36.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (1.25.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (0.43.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (13.7.1)\n","Collecting namex (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text)\n","  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n","Collecting optree (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text)\n","  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (2024.2.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text) (3.0.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (0.1.2)\n","Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow, tensorflow-text\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.2.0\n","    Uninstalling ml-dtypes-0.2.0:\n","      Successfully uninstalled ml-dtypes-0.2.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.9.0\n","    Uninstalling h5py-3.9.0:\n","      Successfully uninstalled h5py-3.9.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.2\n","    Uninstalling tensorboard-2.15.2:\n","      Successfully uninstalled tensorboard-2.15.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.15.0\n","    Uninstalling keras-2.15.0:\n","      Successfully uninstalled keras-2.15.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.3.3 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1 tensorflow-text-2.16.1\n","Collecting datasets\n","  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n","Collecting rouge\n","  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (1.4.2)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Collecting huggingface-hub>=0.21.2 (from datasets)\n","  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.1.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Installing collected packages: xxhash, rouge, dill, multiprocess, huggingface-hub, datasets\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.20.3\n","    Uninstalling huggingface-hub-0.20.3:\n","      Successfully uninstalled huggingface-hub-0.20.3\n","Successfully installed datasets-2.19.0 dill-0.3.8 huggingface-hub-0.22.2 multiprocess-0.70.16 rouge-1.0.1 xxhash-3.4.1\n"]}],"source":["!pip install tensorflow-text\n","!pip install datasets gensim rouge pydot graphviz\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, TimeDistributed, Concatenate, Dropout, Bidirectional, MultiHeadAttention\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","import numpy as np\n","import os\n","import pickle\n","from google.colab import drive\n","from datasets import load_dataset\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"code","source":["\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","model_path = '/content/drive/My Drive/model_BiLSTM_word.h5'\n","history_path = '/content/drive/My Drive/history_BiLSTM_word.pkl'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ya0R7-otIB7B","executionInfo":{"status":"ok","timestamp":1714340484725,"user_tz":240,"elapsed":1361,"user":{"displayName":"Lakshmi Swaminathan","userId":"16891025941418371210"}},"outputId":"7de24b36-9937-4620-8bcf-c63450626915"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.utils import to_categorical\n","\n","# Load dataset\n","dataset = load_dataset(\"neulab/tldr\", split='train')\n","\n","# Append <start> and <end> tokens to cmd_texts\n","cmd_texts = [\"<start>\" + item['cmd'] + \"<end>\" for item in dataset]\n","\n","# Combine nl_texts and cmd_texts for tokenizer fitting\n","nl_texts = [item['nl'] for item in dataset]\n","all_texts = nl_texts + cmd_texts\n","\n","# Initialize and fit tokenizer\n","tokenizer = Tokenizer(filters='', lower=True, split=' ')\n","tokenizer.fit_on_texts(all_texts)\n","vocab_size = len(tokenizer.word_index) + 1  # +1 for zero padding\n","\n","# Prepare sequences\n","nl_sequences = tokenizer.texts_to_sequences(nl_texts)\n","cmd_sequences = tokenizer.texts_to_sequences(cmd_texts)\n","\n","# Determine maximum sequence length\n","max_length = max(max(len(seq) for seq in nl_sequences), max(len(seq) for seq in cmd_sequences))\n","\n","# Pad sequences\n","nl_sequences_padded = pad_sequences(nl_sequences, maxlen=max_length, padding='post')\n","cmd_sequences_padded = pad_sequences(cmd_sequences, maxlen=max_length, padding='post')\n","\n","# Prepare decoder input data and target data\n","decoder_input_data = np.zeros_like(cmd_sequences_padded)\n","decoder_input_data[:, 1:] = cmd_sequences_padded[:,:-1]\n","num_classes = vocab_size  # Set num_classes to vocab_size\n","decoder_target_data = to_categorical(cmd_sequences_padded, num_classes=num_classes)\n"],"metadata":{"id":"iBbEIfnyIkJn","executionInfo":{"status":"ok","timestamp":1714340465444,"user_tz":240,"elapsed":5042,"user":{"displayName":"Lakshmi Swaminathan","userId":"16891025941418371210"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Confirming the shapes\n","print(nl_sequences_padded.shape)  # Expected shape: (batch_size, sequence_length)\n","print(decoder_input_data.shape)   # Expected shape: (batch_size, sequence_length)\n","# Convert cmd_sequences_padded to categorical\n","cmd_sequences_padded = to_categorical(cmd_sequences_padded, num_classes=num_classes)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PtaynxTfGStJ","executionInfo":{"status":"ok","timestamp":1714340470083,"user_tz":240,"elapsed":998,"user":{"displayName":"Lakshmi Swaminathan","userId":"16891025941418371210"}},"outputId":"c14523ab-a520-4657-9fbc-e218f59d35af"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["(6414, 34)\n","(6414, 34)\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.initializers import Orthogonal\n","# Check if model exists and load or create new\n","if os.path.exists(model_path):\n","    print(\"Loading existing model...\")\n","    model = load_model(model_path)\n","    with open(history_path, 'rb') as f:\n","        history = pickle.load(f)\n","else:\n","    print(\"Creating new model...\")\n","    embedding_dim = 128\n","    units = 128\n","\n","    # Build the model\n","    encoder_inputs = Input(shape=(None,))\n","    encoder_emb = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(encoder_inputs)\n","    encoder_lstm = Bidirectional(LSTM(units, return_sequences=True, return_state=True))\n","    encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_lstm(encoder_emb)\n","    encoder_states = [Concatenate()([forward_h, backward_h]), Concatenate()([forward_c, backward_c])]\n","\n","    decoder_inputs = Input(shape=(None,))\n","    decoder_emb = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(decoder_inputs)\n","    decoder_lstm = LSTM(units * 2, return_sequences=True, return_state=True)\n","    decoder_outputs, _, _ = decoder_lstm(decoder_emb, initial_state=encoder_states)\n","\n","    # Attention\n","    attn_layer = MultiHeadAttention(num_heads=4, key_dim=128)\n","    attn_out = attn_layer(query=decoder_outputs, key=encoder_outputs, value=encoder_outputs)\n","    decoder_concat_input = Concatenate(axis=-1)([decoder_outputs, attn_out])\n","\n","    decoder_dense = TimeDistributed(Dense(vocab_size, activation='softmax'))\n","    decoder_outputs = decoder_dense(decoder_concat_input)\n","\n","    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","\n","    # Train the model\n","    checkpoint = ModelCheckpoint(model_path + \".keras\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n","\n","    # Now, fit the model\n","    history = model.fit(\n","        [nl_sequences_padded, decoder_input_data],  # Encoder and Decoder inputs\n","        decoder_target_data,                        # Target outputs\n","        batch_size=64,\n","        epochs=100,\n","        validation_split=0.2,\n","        callbacks=[checkpoint, early_stopping]\n","    )\n","\n","    history = history.history\n","\n","    # Save the model and history\n","    model.save(model_path + \".keras\")\n","    with open(history_path, 'wb') as f:\n","        pickle.dump(history, f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"fTKSP6msGwxD","executionInfo":{"status":"ok","timestamp":1714340646097,"user_tz":240,"elapsed":133564,"user":{"displayName":"Lakshmi Swaminathan","userId":"16891025941418371210"}},"outputId":"999a6c49-28ef-4a23-9079-2c10fc7054c8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new model...\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional_1\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │      \u001b[38;5;34m1,726,464\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ bidirectional             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),    │        \u001b[38;5;34m263,168\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n","│ (\u001b[38;5;33mBidirectional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │                        │\n","│                           │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     │                │                        │\n","│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]           │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │      \u001b[38;5;34m1,726,464\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],   │\n","│                           │                        │                │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m3\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n","│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m4\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),    │        \u001b[38;5;34m394,240\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n","│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n","│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m526,080\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n","│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n","│                           │                        │                │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n","│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ time_distributed          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13488\u001b[0m)    │      \u001b[38;5;34m6,919,344\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │                        │                │                        │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,726,464</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ bidirectional             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │                        │\n","│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │                │                        │\n","│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]           │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,726,464</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],   │\n","│                           │                        │                │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n","│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n","│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │                │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">526,080</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n","│                           │                        │                │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ time_distributed          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13488</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,919,344</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │                        │                │                        │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,555,760\u001b[0m (44.08 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,555,760</span> (44.08 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,555,760\u001b[0m (44.08 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,555,760</span> (44.08 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.8390 - loss: 3.6271\n","Epoch 1: val_loss improved from inf to 1.45884, saving model to /content/drive/My Drive/model_BiLSTM_word.h5.keras\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 234ms/step - accuracy: 0.8396 - loss: 3.6090 - val_accuracy: 0.8906 - val_loss: 1.4588\n","Epoch 2/100\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.8966 - loss: 1.0279\n","Epoch 2: val_loss improved from 1.45884 to 1.08317, saving model to /content/drive/My Drive/model_BiLSTM_word.h5.keras\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - accuracy: 0.8966 - loss: 1.0273 - val_accuracy: 0.8909 - val_loss: 1.0832\n","Epoch 3/100\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.8950 - loss: 0.8497\n","Epoch 3: val_loss did not improve from 1.08317\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.8950 - loss: 0.8496 - val_accuracy: 0.8907 - val_loss: 1.1399\n","Epoch 4/100\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.8950 - loss: 0.8020\n","Epoch 4: val_loss did not improve from 1.08317\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.8950 - loss: 0.8019 - val_accuracy: 0.8865 - val_loss: 1.1463\n","Epoch 5/100\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.8964 - loss: 0.7515\n","Epoch 5: val_loss did not improve from 1.08317\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.8964 - loss: 0.7516 - val_accuracy: 0.8896 - val_loss: 1.1858\n","Epoch 6/100\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.8970 - loss: 0.7205\n","Epoch 6: val_loss did not improve from 1.08317\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.8970 - loss: 0.7206 - val_accuracy: 0.8844 - val_loss: 1.2085\n","Epoch 7/100\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.8982 - loss: 0.6892\n","Epoch 7: val_loss did not improve from 1.08317\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.8982 - loss: 0.6893 - val_accuracy: 0.8834 - val_loss: 1.2456\n"]}]},{"cell_type":"code","source":["# Calculate BLEU, ROUGE, and perplexity for validation data\n","from nltk.translate.bleu_score import sentence_bleu\n","from rouge import Rouge\n","from nltk.translate.bleu_score import sentence_bleu\n","from rouge import Rouge\n","import numpy as np\n","\n","def evaluate_model(model, tokenizer, nl_sequences_padded, cmd_sequences_padded, max_length, vocab_size, history):\n","    # Prepare the input and output for validation\n","    val_indices = int(len(nl_sequences_padded) * 0.8)  # Assuming validation_split=0.2\n","    val_nl_padded = nl_sequences_padded[val_indices:]\n","    val_cmd_padded = cmd_sequences_padded[val_indices:]\n","\n","    # Check if cmd_sequences_padded is one-hot encoded, convert if necessary\n","    if val_cmd_padded.ndim == 3:\n","        val_cmd_padded = np.argmax(val_cmd_padded, axis=-1)\n","\n","    # Initialize val_decoder_input_data correctly using explicit shape and data type\n","    val_decoder_input_data = np.zeros((val_cmd_padded.shape[0], val_cmd_padded.shape[1]), dtype=int)\n","    val_decoder_input_data[:, 1:] = val_cmd_padded[:, :-1]  # Shift cmd data for decoder input\n","\n","    # Ensure it's 2D and print the shape\n","    print(f\"Validation NL input shape: {val_nl_padded.shape}\")\n","    print(f\"Validation CMD input shape: {val_decoder_input_data.shape}\")\n","    if val_decoder_input_data.ndim != 2:\n","        raise ValueError(\"Decoder input data should be 2D. Check data preparation steps.\")\n","\n","    # Predict the command sequences\n","    predictions = model.predict([val_nl_padded, val_decoder_input_data])\n","\n","    # Convert predictions to text\n","    predicted_texts = []\n","    for prediction in predictions:\n","        sequence = np.argmax(prediction, axis=-1)\n","        text = tokenizer.sequences_to_texts([sequence])\n","        predicted_texts.append(text[0])\n","\n","    # Convert actual command sequences to text\n","    actual_texts = tokenizer.sequences_to_texts(val_cmd_padded)\n","\n","    # Compute BLEU and ROUGE scores\n","    bleu_scores = [sentence_bleu([act.split()], pred.split()) for act, pred in zip(actual_texts, predicted_texts)]\n","    rouge = Rouge()\n","    rouge_scores = [rouge.get_scores(pred, act)[0] for pred, act in zip(predicted_texts, actual_texts)]\n","\n","    # Calculate mean BLEU and ROUGE scores\n","    mean_bleu = np.mean(bleu_scores)\n","    rouge_f = np.mean([score['rouge-l']['f'] for score in rouge_scores])\n","\n","    # Calculate perplexity on validation loss\n","    val_loss = history['val_loss'][-1]\n","    perplexity = np.exp(val_loss)\n","\n","    print(f\"Average BLEU Score on Validation: {mean_bleu}\")\n","    print(f\"Average ROUGE-L F-Score on Validation: {rouge_f}\")\n","    print(f\"Perplexity on Validation: {perplexity}\")\n","\n","# Ensure history is correctly passed to the function after the model has been trained\n","evaluate_model(model, tokenizer, nl_sequences_padded, cmd_sequences_padded, max_length, vocab_size, history)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bwnlAsGiKEWC","executionInfo":{"status":"ok","timestamp":1714340668559,"user_tz":240,"elapsed":7550,"user":{"displayName":"Lakshmi Swaminathan","userId":"16891025941418371210"}},"outputId":"b7fbb74d-7dc0-42c7-dd33-8507a7584499"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation NL input shape: (1283, 34)\n","Validation CMD input shape: (1283, 34)\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step\n","Average BLEU Score on Validation: 0.00019935040507600187\n","Average ROUGE-L F-Score on Validation: 0.03405840599370301\n","Perplexity on Validation: 3.475041503589121\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]}]},{"cell_type":"code","source":["def translate(model, tokenizer, text, max_length):\n","    # Tokenize the input text\n","    sequence = tokenizer.texts_to_sequences([text])\n","    sequence_padded = pad_sequences(sequence, maxlen=max_length, padding='post')\n","\n","    # Prepare the decoder input data\n","    decoder_input_data = np.zeros_like(sequence_padded)\n","    decoder_input_data[:, 1:] = sequence_padded[:, :-1]\n","\n","    # Predict\n","    prediction = model.predict([sequence_padded, decoder_input_data])\n","\n","    # Convert prediction to text\n","    predicted_sequence = np.argmax(prediction[0], axis=-1)\n","    predicted_text = tokenizer.sequences_to_texts([predicted_sequence])\n","\n","    # Remove the <start> and <end> tokens\n","    predicted_text_clean = [token for token in predicted_text[0].split() if token not in ['<start>', '<end>']]\n","\n","    # Join the tokens back together\n","    predicted_command = ' '.join(predicted_text_clean)\n","\n","    return predicted_command"],"metadata":{"id":"Yu7tUmQORabG","executionInfo":{"status":"ok","timestamp":1714340788067,"user_tz":240,"elapsed":424,"user":{"displayName":"Lakshmi Swaminathan","userId":"16891025941418371210"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Get the first 10 rows of the training dataset\n","first_10_nl_texts = nl_texts[:10]\n","first_10_cmd_texts = cmd_texts[:10]\n","\n","# Translate each text and print the input, prediction, and actual command\n","for i in range(10):\n","    input_text = first_10_nl_texts[i]\n","    actual_command = first_10_cmd_texts[i]\n","    predicted_command = translate(model, tokenizer, input_text, max_length)\n","\n","    print(f\"Input Text: {input_text}\")\n","    print(f\"Predicted Command: {predicted_command}\")\n","    print(f\"Actual Command: {actual_command}\")\n","    print(\"\\n---\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hhmNnnKaPzNY","executionInfo":{"status":"ok","timestamp":1714340792654,"user_tz":240,"elapsed":1363,"user":{"displayName":"Lakshmi Swaminathan","userId":"16891025941418371210"}},"outputId":"a8d04b18-6002-4816-99c3-90256aa4395f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step\n","Input Text: get the label of a fat32 partition\n","Predicted Command: <start>sudo install {{path/to/file}}<end> {{path/to/file}}<end>\n","Actual Command: <start>fatlabel {{/dev/sda1}}<end>\n","\n","---\n","\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Input Text: set the label of a fat32 partition\n","Predicted Command: <start>sudo pacman -s {{path/to/file}}<end> > > >\n","Actual Command: <start>fatlabel {{/dev/sdc3}} \"{{new_label}}\"<end>\n","\n","---\n","\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Input Text: search for a package in your current sources\n","Predicted Command: <start>sudo -c\n","Actual Command: <start>apt-cache search {{query}}<end>\n","\n","---\n","\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Input Text: show information about a package\n","Predicted Command: <start>sudo list<end>\n","Actual Command: <start>apt-cache show {{package}}<end>\n","\n","---\n","\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Input Text: show whether a package is installed and up to date\n","Predicted Command: <start>git diff\n","Actual Command: <start>apt-cache policy {{package}}<end>\n","\n","---\n","\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Input Text: show dependencies for a package\n","Predicted Command: <start>sudo list<end> {{package_name}}<end>\n","Actual Command: <start>apt-cache depends {{package}}<end>\n","\n","---\n","\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Input Text: show packages that depend on a particular package\n","Predicted Command: <start>sudo commit\n","Actual Command: <start>apt-cache rdepends {{package}}<end>\n","\n","---\n","\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Input Text: refresh database content\n","Predicted Command: <start>sudo -?<end>\n","Actual Command: <start>sudo updatedb<end>\n","\n","---\n","\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Input Text: display file names as soon as they are found\n","Predicted Command: <start>sudo -c {{path/to/directory}}<end>\n","Actual Command: <start>sudo updatedb --verbose<end>\n","\n","---\n","\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Input Text: install a new package\n","Predicted Command: <start>sudo -?<end> {{package_name}}<end> {{package_name}}<end>\n","Actual Command: <start>sudo pacman --sync {{package_name}}<end>\n","\n","---\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ksbzcoPdQ4NU"},"execution_count":null,"outputs":[]}]}